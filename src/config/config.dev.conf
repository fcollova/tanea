# config.dev.conf  
# Configurazione specifica per ambiente di sviluppo

[database]
# PostgreSQL per crawler e link management
url = postgresql://tanea_user:tanea_secure_2024!@localhost:5432/tanea_news
schema = public
pool_size = 5
pool_timeout = 10

[crawler]
# Configurazione crawler
user_agent = TaneaBot/1.0 (+https://tanea.local/bot)
rate_limit = 2.0
max_concurrent = 3
timeout = 15
max_retries = 3
verify_ssl = false

# Rate limiting avanzato
rate_limit_enabled = true
rate_limit_default_rps = 0.5
rate_limit_max_concurrent = 2
rate_limit_back_off_factor = 2.0
rate_limit_max_back_off = 300.0
robots_txt_enabled = true
robots_txt_cache_hours = 24

[web_crawling]
# Configurazione web crawling con file YAML
config_file = web_crawling.yaml
rate_limit_delay = 2.0
max_links_per_site = 25
min_quality_score = 0.3
max_concurrent_requests = 5

# Parametri spider Trafilatura
spider_max_depth = 3
spider_max_pages = 100
spider_max_known_urls = 300
spider_language = it

[weaviate]
# Sviluppo locale
url = http://localhost:8080
# api_key non necessaria per sviluppo locale
# index_name ora gestito dinamicamente tramite domini in domains.yaml
timeout = 30

[embedding]
# Modello base per sviluppo
model_name = sentence-transformers/all-MiniLM-L6-v2

[search]
# Inserire qui le chiavi API per sviluppo
tavily_api_key = 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
# NEWSAPI Chiave
newsapi_api_key = c46a8c4d8a8a418e9e89856aafde700b
max_results = 5

[news]
# Parametri ridotti per sviluppo
max_results = 5
chunk_size = 500

[scheduler]
# Aggiornamenti pi√π frequenti in sviluppo
update_time = 10:00
cleanup_time = 03:00
cleanup_days_old = 7
check_interval = 30

[logging]
# Configurazioni logging sviluppo
logs_base_dir = logs
crawler_report_dir = logs/crawler_report
enable_report_generation = true
report_formats = csv,json,pdf
report_cleanup_days = 7
log_level = INFO

# Domini configurati ora tramite domains.yaml
# I max_results per ambiente sono specificati nel file YAML