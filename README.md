# ğŸŒ Tanea - Sistema di Web Crawling e Analisi Intelligente

**Tanea** Ã¨ un sistema avanzato di web crawling e analisi di contenuti multi-dominio con storage ibrido (PostgreSQL + Weaviate) e architettura modulare.

## ğŸš€ Caratteristiche Principali

- **ğŸ•·ï¸ Web Crawling Intelligente**: Trafilatura-based per estrazione contenuti
- **ğŸ¯ Multi-Dominio**: Gestione separata domini (calcio, tecnologia, general, etc.)
- **ğŸ§  Vector Database**: Weaviate per ricerca semantica avanzata
- **ğŸ“Š Storage Ibrido**: PostgreSQL per metadati + Weaviate per contenuti
- **ğŸ” Keyword Filtering**: Filtraggio avanzato basato su relevance scoring
- **âš¡ Async Architecture**: Gestione concurrent crawling e rate limiting
- **ğŸ› ï¸ Strumenti Management**: Suite completa per database operations

## ğŸ“ Struttura Progetto

```
tanea/
â”œâ”€â”€ src/                          # Codice sorgente principale
â”‚   â”œâ”€â”€ config/                   # File configurazione
â”‚   â”‚   â”œâ”€â”€ domains.yaml         # Domini e keywords
â”‚   â”‚   â”œâ”€â”€ web_crawling.yaml    # Siti e impostazioni crawler
â”‚   â”‚   â””â”€â”€ config.conf          # Configurazioni globali
â”‚   â”œâ”€â”€ core/                    # Componenti core
â”‚   â”‚   â”œâ”€â”€ domain_manager.py    # Gestione domini
â”‚   â”‚   â”œâ”€â”€ vector_db_manager.py # Gestione Weaviate
â”‚   â”‚   â””â”€â”€ storage/             # Storage components
â”‚   â”œâ”€â”€ crawler/                 # Sistema crawler
â”‚   â”‚   â”œâ”€â”€ trafilatura_crawler.py # Crawler principale
â”‚   â”‚   â””â”€â”€ content_extractor.py   # Estrazione contenuti
â”‚   â””â”€â”€ weaviate_explorer/       # Interfaccia web Streamlit
â”œâ”€â”€ scripts/                     # Script utilities
â”‚   â”œâ”€â”€ clean_db.sh             # Script bash pulizia DB
â”‚   â”œâ”€â”€ clean_databases.py      # Script Python completo
â”‚   â”œâ”€â”€ list_collections.py     # Lista collezioni Weaviate  
â”‚   â”œâ”€â”€ delete_collection.py    # Elimina collezione specifica
â”‚   â””â”€â”€ quick_reset.py          # Reset rapido database
â”œâ”€â”€ docs/                       # Documentazione completa
â””â”€â”€ README.md                   # Questo file
```

## ğŸ”§ Setup e Installazione

### Prerequisiti
- **Python 3.12+**
- **PostgreSQL 14+** 
- **Weaviate 1.24+**
- **Node.js** (per Prisma)

### Installazione
```bash
# Clone repository
git clone <repository-url>
cd tanea

# Setup virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Setup database
npx prisma generate
npx prisma db push

# Setup Weaviate (Docker)
docker run -d \
  --name weaviate \
  -p 8080:8080 \
  -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \
  -e PERSISTENCE_DATA_PATH='/var/lib/weaviate' \
  cr.weaviate.io/semitechnologies/weaviate:1.24.4
```

## ğŸ¯ Quick Start

### 1. Avvio Crawler
```bash
# Crawler completo tutti i domini attivi
python3 src/crawler/trafilatura_crawler.py

# Crawler dominio specifico
python3 src/crawler/trafilatura_crawler.py --domain calcio
```

### 2. Gestione Database
```bash
# Menu interattivo completo
./clean_db.sh

# Lista collezioni Weaviate
./clean_db.sh  # Seleziona opzione 4

# Reset database completo
./clean_db.sh  # Seleziona opzione 3
```

### 3. Interfaccia Web Explorer
```bash
cd src/weaviate_navigator
streamlit run main.py
```
Accedi a: http://localhost:8501

## ğŸ“š Documentazione

La documentazione completa Ã¨ disponibile nella cartella `docs/`:

| File | Descrizione |
|------|-------------|
| [**CRAWLER_ARCHITECTURE.md**](docs/CRAWLER_ARCHITECTURE.md) | ğŸ—ï¸ Architettura completa del sistema, configurazioni, parametri e flussi |
| [**CRAWLER_USAGE.md**](docs/CRAWLER_USAGE.md) | ğŸš€ Guida utilizzo crawler, comandi e esempi pratici |
| [**CRAWLER_API.md**](docs/CRAWLER_API.md) | ğŸ“¡ Documentazione API e interfacce programmatiche |
| [**DATABASE_CLEANUP.md**](docs/DATABASE_CLEANUP.md) | ğŸ—‚ï¸ Guida completa strumenti pulizia e gestione database |
| [**README_DATABASE_SCRIPTS.md**](docs/README_DATABASE_SCRIPTS.md) | ğŸ”§ Documentazione tecnica script database per sviluppatori |
| [**CACHE_CENTRALIZATION.md**](docs/CACHE_CENTRALIZATION.md) | ğŸ—‚ï¸ Centralizzazione cache modelli embedding (BERTino) |

## ğŸ¯ Domini Supportati

Il sistema supporta crawling multi-dominio con configurazione separata:

| Dominio | Siti Supportati | Keywords Principali |
|---------|-----------------|-------------------|
| **calcio** | Gazzetta dello Sport, Corriere dello Sport, TMW | calcio, Serie A, Champions League, calciomercato |
| **tecnologia** | ANSA Tech | tecnologia, AI, software, hardware |
| **general** | Altri siti | keywords generiche |

Configurazione in: `src/config/domains.yaml`

## ğŸ—‚ï¸ Storage e Database

### PostgreSQL
- **Tabella `Site`**: Metadati siti web
- **Tabella `DiscoveredLink`**: Link scoperti durante crawling
- **Connection**: Prisma ORM con async support

### Weaviate (Vector Database)
- **Indici per Dominio**: `Tanea_[Domain]_[Environment]`
- **Schema**: Documenti con metadati e embeddings
- **Search**: Ricerca semantica avanzata

## ğŸ› ï¸ Strumenti di Gestione

### Script Database
```bash
./clean_db.sh                    # Menu interattivo principale
python3 scripts/clean_databases.py    # Menu Python completo
python3 scripts/list_collections.py   # Lista collezioni
python3 scripts/delete_collection.py  # Elimina collezione specifica
```

### Opzioni Disponibili
- âœ… Verifica stato database
- âœ… Pulizia PostgreSQL e/o Weaviate
- âœ… Reset completo con creazione schemi
- âœ… Gestione granulare collezioni Weaviate
- âœ… Procedure sicure con conferme

## âš™ï¸ Configurazione

### File Principali
- **`src/config/domains.yaml`**: Domini, keywords, indici Weaviate
- **`src/config/web_crawling.yaml`**: Siti web, selectors, impostazioni
- **`src/config/config.conf`**: Configurazioni globali (embeddings, cache)

### Parametri Chiave
- **Rate Limiting**: Controllo carico server
- **Keyword Scoring**: Relevance filtering avanzato
- **Content Extraction**: Selectors CSS per ogni sito
- **Domain Mapping**: Assegnazione siti a domini

## ğŸš¨ Sicurezza e Manutenzione

### Operazioni Sicure
- **Conferme Esplicite**: `RESET` per reset completo, `DELETE` per eliminazioni
- **Backup Raccomandato**: Prima di operazioni distruttive
- **Resource Management**: Chiusura automatica connessioni

### Troubleshooting
- **Connection Issues**: Verifica servizi PostgreSQL e Weaviate attivi
- **Import Errors**: Verifica virtual environment e paths
- **Memory Leaks**: Gestione automatica resource cleanup

## ğŸ¤ Sviluppo

### Architettura Modulare
- **`core/`**: Domain manager, vector DB manager, storage
- **`crawler/`**: Web crawler, content extractor
- **`storage/`**: Database managers per PostgreSQL e Weaviate

### Pattern Utilizzati
- **Async/Await**: Per operazioni I/O non-bloccanti
- **Domain-Driven Design**: Separazione per domini semantici
- **Factory Pattern**: Per inizializzazione database managers
- **Resource Management**: Context managers e cleanup automatico

## ğŸ“Š Monitoraggio

### Logging
- **Crawler Operations**: Log dettagliati discovery ed estrazione
- **Database Operations**: Tracking inserimenti e aggiornamenti
- **Error Handling**: Gestione eccezioni con retry logic

### Metriche
- **Articoli per Dominio**: Tracking contenuti estratti
- **Performance**: Rate limiting e tempi di risposta
- **Quality Scoring**: Relevance threshold e filtering

## ğŸ“ License

[Specificare licenza del progetto]

## ğŸ†˜ Supporto

Per questioni tecniche:
1. Consulta la [documentazione completa](docs/)
2. Verifica [troubleshooting](docs/DATABASE_CLEANUP.md#troubleshooting)
3. Apri issue su repository

---

**Tanea v2.1** - Sistema di Web Crawling e Analisi Intelligente Multi-Dominio  
*Ultima modifica: 22 Luglio 2025*